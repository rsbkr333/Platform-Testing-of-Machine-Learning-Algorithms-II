{"cells":[{"cell_type":"code","source":["# Author: Srinivasa Rudraraju\n#Description: Spark ML code in Python to access datasets from Amazon S3, train models on standard algorithms in ML packages and perform gridsearch on each of the algorithms"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Replace with your values\n# NOTE: Set the access to this notebook appropriately to protect the security of your keys.\n# Or you can delete this cell after you run the mount command below once successfully.\nimport urllib\nACCESS_KEY = \"AKIAIO4R3NCSNWJ2CDGA\"\nSECRET_KEY = urllib.quote(\"WjEl1E8wRDpuDoqT3h15WtYJkC3h6bqOcFxgIWgz\")\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"platformtesting\"\nMOUNT_NAME = \"pftestingmountdataset1\""],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Disable warnings and load Pandas package\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# PRINT START TIME\nimport datetime\ndatetime.datetime.now()\n\ntrainData = sqlContext.read.load('/mnt/pftestingmountdataset1/1/01covtype-TrainingSplit1.csv',\n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n\ntrainData.cache()\ntrainData.printSchema()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["pd.DataFrame(trainData.take(5), columns=trainData.columns).transpose()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml.linalg import Vectors\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\ndef vectorizeData(data):\n    return data.rdd.map(lambda r: [r[-1]-1, Vectors.dense(r[:-1])]).toDF(['label','features'])\n\nvectorized_CV_data = vectorizeData(trainData) \n\n# Index labels, adding metadata to the label column\nlabelIndexer = StringIndexer(inputCol='label',outputCol='indexedLabel').fit(vectorized_CV_data)\n\n# Automatically identify categorical features and index them\nfeatureIndexer = VectorIndexer(inputCol='features',outputCol='indexedFeatures').fit(vectorized_CV_data)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# RECORD START TIME\nimport datetime\ntimestart = datetime.datetime.now()\n\n# Train a DecisionTree model\ndTree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures')\n\n# Chain indexers and tree in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, dTree])\n\n# Search through decision tree's maxDepth parameter for best model\nparamGrid = ParamGridBuilder().addGrid(dTree.maxDepth, (3,10))\\\n                              .addGrid(dTree.maxBins, (50,200))\\\n                              .build()\n\n# Set F-1 score as evaluation metric for best model selection\nevaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',\n                                              predictionCol='prediction', metricName='f1')    \n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=2)\n\nCV_model = crossval.fit(vectorized_CV_data)\n\n# Fetch best model\ntree_model = CV_model.bestModel.stages[2]\n\n# PRINT ELAPSED TIME\ntimeend = datetime.datetime.now()\ntimedelta = round((timeend-timestart).total_seconds(), 2) \nprint \"Time taken to execute above cell: \" + str(timedelta) + \" seconds\"\n\nprint tree_model"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["for i in range(1,11):\n  \n  testData = sqlContext.read.load('/mnt/pftestingmountdataset1/1/01covtype-CVSplit'+str(i)+'.csv', format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n    \n  vectorized_test_data = vectorizeData(testData)\n\n  transformed_data = CV_model.transform(vectorized_test_data)\n  print evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n\n  predictions = transformed_data.select('label', 'prediction')\n  predictions.toPandas().head()\n                                                                             "],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# RECORD START TIME\nimport datetime\ntimestart = datetime.datetime.now()\n\n# Train a DecisionTree model\nrForest = RandomForestClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures')\n\n# Chain indexers and tree in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, rForest])\n\n# Search through decision tree's maxDepth parameter for best model\nparamGrid = ParamGridBuilder().addGrid(rForest.maxDepth, (3,10))\\\n                              .addGrid(rForest.maxBins, (50,200))\\\n                              .build()\n\n# Set F-1 score as evaluation metric for best model selection\nevaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',predictionCol='prediction', metricName='f1')    \n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline,estimatorParamMaps=paramGrid,evaluator=evaluator,numFolds=2)\n\nCV_model = crossval.fit(vectorized_CV_data)\n\n# Fetch best model\nrf_model = CV_model.bestModel.stages[2]\n\n# PRINT ELAPSED TIME\ntimeend = datetime.datetime.now()\ntimedelta = round((timeend-timestart).total_seconds(), 2) \nprint \"Time taken to execute above cell: \" + str(timedelta) + \" seconds\"\n\nprint rf_model"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["for i in range(1,11):\n  \n  testData = sqlContext.read.load('/mnt/pftestingmountdataset1/1/01covtype-CVSplit'+str(i)+'.csv', format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n    \n  vectorized_test_data = vectorizeData(testData)\n\n  transformed_data = CV_model.transform(vectorized_test_data)\n  print evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n\n  predictions = transformed_data.select('label', 'prediction')\n  predictions.toPandas().head()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression,OneVsRest\n\n# RECORD START TIME\nimport datetime\ntimestart = datetime.datetime.now()\n\n# Train a DecisionTree model\nlRegression = LogisticRegression(labelCol='indexedLabel', featuresCol='indexedFeatures')\n\nlr = OneVsRest(classifier=lRegression)\n\n# Chain indexers and tree in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, lr])\n\n# Search through decision tree's maxDepth parameter for best model\nparamGrid = ParamGridBuilder().addGrid(lRegression.regParam, (0.01,0.1))\\\n                              .addGrid(lRegression.maxIter, (5,15))\\\n                              .build()\n        \n# Set F-1 score as evaluation metric for best model selection\nevaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',predictionCol='prediction',metricName='f1')    \n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline,estimatorParamMaps=paramGrid,evaluator=evaluator,numFolds=2)\n\nCV_model = crossval.fit(vectorized_CV_data)\n\n# Fetch best model\nlr_model = CV_model.bestModel.stages[2]\n\n# PRINT ELAPSED TIME\ntimeend = datetime.datetime.now()\ntimedelta = round((timeend-timestart).total_seconds(), 2) \nprint \"Time taken to execute above cell: \" + str(timedelta) + \" seconds\"\n\nprint lr_model"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["for i in range(1,11):\n  \n  testData = sqlContext.read.load('/mnt/pftestingmountdataset1/1/01covtype-CVSplit'+str(i)+'.csv', format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n    \n  vectorized_test_data = vectorizeData(testData)\n\n  transformed_data = CV_model.transform(vectorized_test_data)\n  print evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n\n  predictions = transformed_data.select('label', 'prediction')\n  predictions.toPandas().head()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.classification import MultilayerPerceptronClassifier\n\n# RECORD START TIME\nimport datetime\ntimestart = datetime.datetime.now()\n\nlayers = [54,20,10,7]\n# Train a DecisionTree model\nmlPreceptron = MultilayerPerceptronClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures',layers=layers)\n\n# Chain indexers and tree in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, mlPreceptron])\n\n# Search through decision tree's maxDepth parameter for best model\nparamGrid = ParamGridBuilder().addGrid(mlPreceptron.blockSize, (128, 256))\\\n                              .addGrid(mlPreceptron.maxIter, (5, 10))\\\n                              .build()\n        \n# Set F-1 score as evaluation metric for best model selection\nevaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',predictionCol='prediction', metricName='f1')    \n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline,estimatorParamMaps=paramGrid,evaluator=evaluator,numFolds=2)\n\nCV_model = crossval.fit(vectorized_CV_data)\n\n# Fetch best model\nmlp_model = CV_model.bestModel.stages[2]\n\n# PRINT ELAPSED TIME\ntimeend = datetime.datetime.now()\ntimedelta = round((timeend-timestart).total_seconds(), 2) \nprint \"Time taken to execute above cell: \" + str(timedelta) + \" seconds\"\n\nprint mlp_model"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["for i in range(1,11):\n  \n  testData = sqlContext.read.load('/mnt/pftestingmountdataset1/1/01covtype-CVSplit'+str(i)+'.csv', format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n    \n  vectorized_test_data = vectorizeData(testData)\n\n  transformed_data = CV_model.transform(vectorized_test_data)\n  print evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n\n  predictions = transformed_data.select('label', 'prediction')\n  predictions.toPandas().head()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.feature import MinMaxScaler\n\n# RECORD START TIME\nimport datetime\ntimestart = datetime.datetime.now()\n\nscaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n\n# Compute summary statistics and generate MinMaxScalerModel\nscalerModel = scaler.fit(vectorized_CV_data)\n\n# rescale each feature to range [min, max].\nscaledData = scalerModel.transform(vectorized_CV_data)\nscaledData.show()\n\n# Train a NaiveBayes model\nnb = NaiveBayes(labelCol=\"indexedLabel\", featuresCol=\"scaledFeatures\", modelType=\"multinomial\")\n\n# Chain indexers and tree in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, nb])\n\n# Search through decision tree's maxDepth parameter for best model\n# Create ParamGrid and Evaluator for Cross Validation\nparamGrid = ParamGridBuilder().addGrid(nb.smoothing, (0.0,1.0)).build()\n        \n# Set F-1 score as evaluation metric for best model selection\nevaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid,evaluator=evaluator,numFolds=2)\n\nCV_model = crossval.fit(scaledData)\n\n# Fetch best model\nnb_model = CV_model.bestModel.stages[2]\n\n# PRINT ELAPSED TIME\ntimeend = datetime.datetime.now()\ntimedelta = round((timeend-timestart).total_seconds(), 2) \nprint \"Time taken to execute above cell: \" + str(timedelta) + \" seconds\"\n\nprint nb_model"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["for i in range(1,11):\n  \n  testData = sqlContext.read.load('/mnt/pftestingmountdataset1/1/01covtype-CVSplit'+str(i)+'.csv', format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n    \n  vectorized_test_data = vectorizeData(testData)\n  \n  scalerTestModel = scaler.fit(vectorized_test_data)\n  scaledTestData = scalerTestModel.transform(vectorized_test_data)\n\n  transformed_data = CV_model.transform(scaledTestData)\n  print evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n\n  predictions = transformed_data.select('label', 'prediction')\n  predictions.toPandas().head()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["predictions.toPandas()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"ForestCovDataset1","notebookId":990985226908886},"nbformat":4,"nbformat_minor":0}
